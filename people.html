<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>People | OpenDataLab</title>
  <link rel="stylesheet" href="css/style.css">
  <script src="js/main.js" defer></script>
</head>
<body>
  <header>
    <div class="container nav-container">
      <nav>
        <a href="index.html">Home</a>
        <a href="research.html">Research</a>
        <a href="people.html" class="active">People</a>
        <a href="publications.html">Publications</a>
        <a href="news.html">News</a>
        <a href="resources.html">Resources</a>
        <a href="opportunity.html">Opportunities</a>
      </nav>
    </div>
  </header>  
  <main>
    <!-- content-wrapper 将由JavaScript添加包裹 -->
    <section class="people-section">
      <div class="container">

        <h2>Faculty & Researchers</h2>
        <hr style="margin-bottom: 2em;">

        <div class="pi-card person-detailed-profile" style="margin-bottom: 3em;">
          <div class="profile-left-column">
            <div class="pi-image">
              <img src="assets/images/conghui.PNG" alt="Dr. Conghui He" class="pi-avatar">
            </div>
            <h3>Conghui He (何聪辉)</h3>
            <p class="pi-title">Young Scientist and Project Investigator (PI) at Shanghai Artificial Intelligence Laboratory</p>
            <p>Previously Senior Researcher at WeChat (developed Plato).</p>
            <p>Ph.D. from Tsinghua University (2013-2018), B.S. from Sun Yat-sen University (2009-2013).</p>
            <p>Email: <a href="mailto:heconghui@pjlab.org.cn">heconghui@pjlab.org.cn</a></p>
            <div class="pi-social">
              <a href="https://conghui.github.io/" target="_blank" rel="noopener noreferrer">Personal Homepage</a> |
              <a href="https://scholar.google.com/citations?user=PopTv7kAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a>
            </div>
          </div>
          <div class="profile-right-column">
            <h4>Research Interests</h4>
            High-Performance Computing, Computer Vision, Large Language Models, Data-Centric AI, Pre-training Data Preparation, Multimodal Learning
            <h4>Awards</h4>
            <ul>
              <li>2023 SenseTime Award (Top 1 team out of 100)</li>
              <li>2021 SenseTime Outstanding Team Award (Top 10 teams out of 200)</li>
              <li>2019 Tencent Technology Breakthrough Award - Gold (Top 1 team out of 50)</li>
              <li>2018 Outstanding Doctoral Graduate Award</li>
              <li>2017 ACM Gordon Bell Prize (Highest honor in HPC applications)</li>
              <li>2013 IEEE-IBM Smarter Planet Challenge Global Winner (Team Leader, 1/54)</li>
            </ul>

            <h4>Key Research, Projects & Reports</h4>
            <ul>
              <li><strong><a href="https://opendatalab.com/" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">OpenDataLab:</a></strong> An open platform with 7700+ datasets, serving 40k+ developers.</li>
              <li><strong><a href="https://github.com/opendatalab/MinerU" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">MinerU:</a></strong> A one-stop, open-source, high-quality data extraction tool for PDF, web, and e-books.</li>
              <li><strong><a href="https://github.com/InternLM/InternLM" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">InternLM:</a></strong> Series of 7B and 20B foundation and chat models.</li>
              <li><strong><a href="https://github.com/opendatalab/PDF-Extract-Kit" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">PDF-Extract-Kit:</a></strong> A comprehensive library for high-quality PDF content extraction.</li>
              <li>Report: <a href="https://www.sohu.com/a/863631470_115565?scm=thor.521_14-200000.0.0.&spm=smpc.home.it-news11.10.17405316000165oXoZw5_1467&_trans_=060008_lym" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"对话上海AI Lab何聪辉：从DeepSeek看数据的重要性，低成本实现"四两拨千斤""</a></li>
              <li>Report: <a href="https://www.thepaper.cn/newsDetail_forward_1868855" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"中国超算再获"戈登贝尔奖"，成果对地震预测研究有借鉴意义"</a></li>
            </ul>

            <h4>Selected Publications</h4>
            <ul>
              <li>Image Over Text: Transforming Formula Recognition Evaluation with Character Detection Matching, CVPR 2025</li>
              <li>OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations, CVPR 2025</li>
              <li>GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training, ICLR 2025</li>
              <li>OmniCorpus: A Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text, ICLR 2025</li>
              <li>Mmbench: Is your multi-modal model an all-around player? ECCV 2024</li>
            </ul>
          </div>
        </div>

        <div class="pi-card person-detailed-profile" style="margin-bottom: 3em;">
          <div class="profile-left-column">
            <div class="pi-image">
              <img src="assets/images/lijun.PNG" alt="Dr. Jun Li" class="pi-avatar">
            </div>
            <h3>Lijun Wu (吴郦军)</h3>
            <p class="pi-title">Young Scientist, Shanghai Artificial Intelligence Laboratory.</p>
            <p>Formerly Research Scientist at ByteDance, Senior Researcher at Microsoft Research Asia (MSRA).</p>
            <p>Email: <a href="mailto:lijun_wu@outlook.com">lijun_wu@outlook.com</a></p>
            <div class="pi-social">
              <a href="https://apeterswu.github.io/" target="_blank" rel="noopener noreferrer">Personal Homepage</a> |
              <a href="https://scholar.google.com/citations?user=RD5kSG0AAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a>
            </div>
          </div>
          <div class="profile-right-column">
            <h4>Research Interests</h4>
            LLM (post-training, RLHF), Synthetic Data Optimization, AI4Science (LLM4Science, Drug Discovery)
            <h4>Awards</h4>
            <ul>
              <li>2013 IEEE-IBM Smarter Planet Challenge Global Winner</li>
              <li>2018 MSRA Ph.D. Fellowship</li>
              <li>2019 WMT Global Machine Translation Competition - 8 Track Championships</li>
              <li>2021 OGB-LSC@KDD Cup - Runner up</li>
              <li>2024 ACL Language + Molecule - 1st and 2nd place in two tracks</li>
            </ul>

            <h4>Key Research, Projects & Reports</h4>
            <ul>
              <li>Report: <a href="https://www.microsoft.com/en-us/research/articles/machine-translation-news-test-set-human-parity/" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"2018全球首个人工媲美的中英机器翻译系统"</a></li>
              <li>Report: <a href="https://www.microsoft.com/en-us/research/articles/wmt-2019/" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"A study of reinforcement learning for neural machine translation"</a></li>
              <li>Report: <a href="https://www.spaces.ac.cn/archives/8496" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"WMT 2019国际机器翻译大赛：微软亚洲研究院以8项第一成为冠军"</a></li>
              <li>Report: <a href="https://www.microsoft.com/en-us/research/articles/a-survey-on-non-autoregressive-generation/" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"R-Drop: A simple and effective regular method to correct the defects of Dropout"</a></li>
              <li>Report: <a href="https://www.jiqizhixin.com/articles/2023-11-16-3" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"非自回归生成研究最新综述，近200篇文献揭示挑战和未来方向"</a></li>
              <li>Report: <a href="https://www.jiqizhixin.com/articles/2023-11-16-3" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"230页长文，涵盖5大科学领域，微软团队使用GPT-4探索LLM对科学发现的影响"</a></li>
              <li>Report: <a href="https://www.microsoft.com/en-us/research/articles/tamgen/" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"加速药物发现：基于生成式AI的靶点感知分子生成器TamGen"</a></li>
              <li>Report: <a href="https://info.genophore.com/posts/fabind-how-enhanced-pocket-prediction-and-pose-generation-can-transform-your-molecular-docking" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"NatureLM：驱动科学发现与创新的跨领域AI大模型"</a></li>
            </ul>

            <h4>Selected Publications</h4>
            <ul>
              <li>Nature Language Model: Deciphering the Language of Nature for Scientific Discovery, arxiv 2025</li>
              <li>3D-MolT5: Towards Unified 3D Molecule-Text Modeling with 3D Molecular Tokenization, ICLR 2025</li>
              <li>Fabind+: Enhancing molecular docking through improved pocket prediction and pose generation, KDD 2025</li>
              <li>Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey, arxiv 2024</li>
              <li>Target-aware Molecule Generation for Drug Design Using a Chemical Language Model, Nature Communications, 2024</li>
            </ul>
          </div>
        </div>

        <div class="pi-card person-detailed-profile" style="margin-bottom: 3em;">
          <div class="profile-left-column">
            <div class="pi-image">
              <img src="assets/images/wangbin.PNG" alt="Dr. Bin Wang" class="pi-avatar">
            </div>
            <h3>Bin Wang (王斌)</h3>
            <p class="pi-title">Young Researcher, Shanghai Artificial Intelligence Laboratory.</p>
            <p>Ph.D. from University of Chinese Academy of Sciences (UCAS Scholar).</p>
            <p>Algorithm Lead for MinerU project.</p>
            <p>Email: <a href="mailto:wangbin@pjlab.org.cn">wangbin@pjlab.org.cn</a></p>
            <div class="pi-social">
              <a href="https://wangbindl.github.io" target="_blank" rel="noopener noreferrer">Personal Homepage</a> |
              <a href="https://scholar.google.com/citations?user=WljXYoYAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar</a> |
              <a href="https://github.com/wangbinDL" target="_blank" rel="noopener noreferrer">GitHub</a>
            </div>
          </div>
          <div class="profile-right-column">
            <h4>Research Interests</h4>
            Intelligent Document Parsing and Understanding, Data Autonomous Iteration Agents, Multimodal Large Models
            <h4>Awards</h4>
            <ul>
              <li>ImageNet Large Scale Visual Recognition Challenge (ILSVRC2016 VID) - 3rd Place Globally</li>
              <li>UCAS Zhu Li Yuehua Excellent Doctoral Scholarship</li>
            </ul>
            
            <h4>Key Research & Projects</h4>
            <ul>
              <li><strong>MinerU:</strong> <a href="https://github.com/opendatalab/MinerU" target="_blank" rel="noopener noreferrer">https://github.com/opendatalab/MinerU</a></li>
              <li><strong>PDF-Extract-Kit:</strong> <a href="https://github.com/opendatalab/PDF-Extract-Kit" target="_blank" rel="noopener noreferrer">https://github.com/opendatalab/PDF-Extract-Kit</a></li>
              <li><strong>DocLayout-YOLO:</strong> <a href="https://github.com/opendatalab/DocLayout-YOLO" target="_blank" rel="noopener noreferrer">https://github.com/opendatalab/DocLayout-YOLO</a></li>
              <li><strong>OmniDocBench:</strong> <a href="https://github.com/opendatalab/OmniDocBench" target="_blank" rel="noopener noreferrer">https://github.com/opendatalab/OmniDocBench</a></li>
            </ul>

            <h4>Research Focus Areas</h4>
            <ul>
              <li><strong>Intelligent Document Parsing & Understanding:</strong> Developing practical algorithms for layout detection, table recognition, chemical element recognition, geometric parsing, etc., for RAG and AI4S.</li>
              <li><strong>Multimodal Large Models:</strong> Focusing on vertical domain multimodal large models using data-centric algorithms, generative models, and reinforcement learning to address OOD problems.</li>
              <li><strong>Data Autonomous Iteration Agents:</strong> Using agent technology to automate data iteration processes (quality improvement, distribution balancing, safety validation) for efficient AI model training.</li>
            </ul>

            <h4>Selected Publications</h4>
            <ul>
              <li>Image Over Text: Transforming Formula Recognition Evaluation with Character Detection Matching, CVPR 2025</li>
              <li>OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations, CVPR 2025</li>
              <li>GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training, ICLR 2025</li>
              <li>OmniCorpus: A Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text, ICLR 2025</li>
              <li>MinerU: An Open-Source Solution for Precise Document Content Extraction, Arxiv 2024</li>
            </ul>
          </div>
        </div>

        <div class="pi-card person-detailed-profile" style="margin-bottom: 3em;">
          <div class="profile-left-column">
            <div class="pi-image">
              <img src="assets/images/wujiang.PNG" alt="Dr. Jiang Wu" class="pi-avatar">
            </div>
            <h3>Jiang Wu (吴江)</h3>
            <p class="pi-title">Young Researcher, Shanghai Artificial Intelligence Laboratory.</p>
            <p>B.S. and Ph.D. from Tsinghua University.</p>
            <p>Email: <a href="mailto:wujiang@pjlab.org.cn">wujiang@pjlab.org.cn</a></p>
            <div class="pi-social">
              <a href="https://scholar.google.com/citations?user=LHiiL7AAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar</a>
            </div>
          </div>
          <div class="profile-right-column">
            <h4>Research Interests</h4>
            Large Language Models, Multimodal Large Models, Intelligent Document Parsing and Understanding
            <h4>Awards</h4>
            <ul>
              <li>Led the development of an industry-leading satellite imagery analysis system, setting new technical benchmarks, and deployed it in multiple satellite and surveying centers.</li>
            </ul>
            <h4>Selected Publications</h4>
            <ul>
              <li>Benchmarking Chinese Commonsense Reasoning of LLMs: From Chinese-Specifics to Reasoning-Memorization Correlations, ACL 2024</li>
              <li>VHM: Versatile and Honest Vision Language Model for Remote Sensing Image Analysis, AAAI 2025</li>
              <li>Utilize the Flow Before Stepping into the Same River Twice: Certainty Represented Knowledge Flow for Refusal-Aware Instruction Tuning, AAAI 2025</li>
              <li>GRAIT: Gradient-Driven Refusal-Aware Instruction Tuning for Effective Hallucination Mitigation, NAACL 2025 findings</li>
              <li>OpenHuEval: Evaluating Large Language Model on Hungarian Specifics, arxiv 2025</li>
            </ul>
          </div>
        </div>

        <div class="pi-card person-detailed-profile" style="margin-bottom: 3em;">
          <div class="profile-left-column">
            <div class="pi-image">
              <img src="assets/images/jiantao.PNG" alt="Dr. Jiantao Qiu" class="pi-avatar">
            </div>
            <h3>Jiantao Qiu (邱剑涛)</h3>
            <p class="pi-title">Young Researcher, Shanghai Artificial Intelligence Laboratory.</p>
            <p>B.S. and Ph.D. in Electronic Engineering from Tsinghua University.</p>
            <p>Email: <a href="mailto:qiujiantao@pjlab.org.cn">qiujiantao@pjlab.org.cn</a></p>
            <div class="pi-social">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=Vm8bStkAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar</a>
            </div>
          </div>
          <div class="profile-right-column">
            <h4>Research Interests</h4>
            Large Language Model Datasets, HTML Document Understanding, Energy-Efficient Neural Network Accelerator Design, Multi-Machine Collaborative System Design
            <h4>Awards</h4>
            <ul>
              <li>AI2000 Most Influential Scholar Award Honorable Mention in AAAI/IJCAI (2023, for work in FPGA) - Top 3 Rising Star in FPGA</li>
            </ul>
            
            <h4>Selected Publications</h4>
            <ul>
              <li>Going Deeper with Embedded FPGA Platform for Convolutional Neural Network, FPGA 2016</li>
            </ul>
          </div>
        </div>

        <div class="pi-card person-detailed-profile" style="margin-bottom: 3em;">
          <div class="profile-left-column">
            <div class="pi-image">
              <img src="assets/images/wentao.jpg" alt="Dr. Wentao Zhang" class="pi-avatar">
            </div>
            <h3>Wentao Zhang (张文涛)</h3>
            <p class="pi-title">Assistant Professor, Researcher, and Doctoral Supervisor at the International Machine Learning Research Center, Peking University.<br>Research Consultant at Shanghai Artificial Intelligence Laboratory.</p>
            <p>Formerly at Tencent Machine Learning Platform Department, Apple AIML, and Mila - Quebec AI Institute.</p>
            <p>Email: <a href="mailto:zhangwentao1@pjlab.org.cn">zhangwentao1@pjlab.org.cn</a></p>
            <div class="pi-social">
              <a href="https://scholar.google.com/citations?user=JE4VON0AAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar</a>
            </div>
          </div>
          <div class="profile-right-column">
            <h4>Research Interests</h4>
            Data-centric machine learning and large model data governance.
            <h4>Awards</h4>
            <ul>
              <li>WWW'22 Best Student Paper Award (1/1822)</li>
              <li>AP-Web'23 Best Paper Runner Up Award</li>
              <li>CIKM'24 Best Student Full Paper Award (1/1496)</li>
              <li>Apple Scholar (2021, sole recipient in Asia-Pacific)</li>
              <li>World Artificial Intelligence Conference (WAIC) Yunfan Award (1 of 15 globally)</li>
              <li>Peking University/Beijing Municipal/Chinese Association for Artificial Intelligence Excellent Doctoral Dissertation Award, 2023</li>
              <li>Peking University "Weiming Young Scholar", 2024</li>
              <li>World Internet Conference Leading Scientific and Technological Achievement Award, 2024</li>
              <li>Huawei Spark Award, 2024</li>
              <li>Chinese Institute of Electronics Science and Technology Progress Award (First Prize), 2023</li>
            </ul>

            <h4>Key Research, Projects & Reports</h4>
            <ul>
              <li><strong><a href="https://github.com/Angel-ML/angel" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">Angel</a>:</strong> a high-performance distributed machine learning and graph computing platform, jointly designed by Tencent and PKU.</li>
              <li><strong><a href="https://github.com/PKU-DAIR/SGL" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">SGL</a>:</strong> a scalable graph learning toolkit for extremely large graph datasets.</li>
              <li><strong><a href="https://github.com/PKU-DAIR/mindware" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">MindWare</a>:</strong> a powerful AutoML system, which automates feature engineering, algorithm selection and hyperparameter tuning.</li>
              <li><strong><a href="https://github.com/PKU-DAIR/open-box" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">OpenBox</a>:</strong> an efficient open-source system designed for solving generalized black-box optimization (BBO) problems.</li>
            </ul>

            <h4>Selected Publications</h4>
            <ul>
              <li>PAS: Data-Efficient Plug-and-Play Prompt Augmentation System, ICDE 2025</li>
              <li>DataSculpt: Crafting Data Landscapes for Long-Context LLMs through Multi-Objective Partitioning, ICDE 2025</li>
              <li>Facilitating Multi-turn Function Calling for LLMs via Compositional Instruction Tuning, ICLR 2025</li>
              <li>Towards Precise Scaling Laws for Video Diffusion Transformers, CVPR 2025</li>
              <li>Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models, NeurIPS 2024</li>
            </ul>
          </div>
        </div>

        <div class="pi-card person-detailed-profile" style="margin-bottom: 3em;">
          <div class="profile-left-column">
            <div class="pi-image">
              <img src="assets/images/weijia.PNG" alt="Dr. Weijia Li" class="pi-avatar">
            </div>
            <h3>Weijia Li (李唯嘉)</h3>
            <p class="pi-title">Associate Professor ("Hundred Talents Program"), Sun Yat-sen University.<br>Research Consultant, Shanghai Artificial Intelligence Laboratory.</p>
            <p>Ph.D. from Tsinghua University, Postdoc at MMLab, CUHK.</p>
            <p>Email: <a href="mailto:liweijia@pjlab.org.cn">liweijia@pjlab.org.cn</a></p>
            <div class="pi-social">
              <a href="https://liweijia.github.io/" target="_blank" rel="noopener noreferrer">Personal Homepage</a> |
              <a href="https://scholar.google.com/citations?user=R6Rnh9IAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a>
            </div>
          </div>
          <div class="profile-right-column">
            <h4>Research Interests</h4>
            Multimodal Large Models, Image Generation, Synthetic Data Detection, AI4Earth
            <h4>Key Research, Projects & Reports</h4>
            <ul>
              <li>Report: <a href="https://mp.weixin.qq.com/s/Dio-73BCoYXVyH5zJsK9zg" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"GPT-4o图像生成架构被"破解"了？自回归主干+扩散解码器，还有4o图像生成全面测评基准"</a></li>
              <li>Report: <a href="https://mp.weixin.qq.com/s/SKngVsZtBcgRaqj-zhLgeA" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"ICLR 2025 Spotlight ｜合成数据伪装术 vs 大模型火眼金睛，中大&上海AI Lab提出合成检测基准LOKI"</a></li>
              <li>Report: <a href="https://mp.weixin.qq.com/s/FJIo2TpWEixcS3QA0GCK5g" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"城市复杂环境下具身大模型基准测试！UrBench：综合评估多模态大模型在多视图城市场景中的基准"</a></li>
              <li>Report: <a href="https://mp.weixin.qq.com/s/FJIo2TpWEixcS3QA0GCK5g" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">"论文赏读 | CVPR24 | 结合卫星和街景图像实现精细的建筑属性分割，入选Highlight！"</a></li>
            </ul>

            <h4>Selected Publications</h4>
            <ul>
              <li>LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models (ICLR 2025, Spotlight)</li>
              <li>Urbench: A comprehensive benchmark for evaluating large multimodal models in multi-view urban scenarios (AAAI 2025)</li>
              <li>Gpt-imgeval: A comprehensive benchmark for diagnosing gpt4o in image generation (Arxiv 2025)</li>
              <li>LEGION: Learning to Ground and Explain for Synthetic Image Detection (Arxiv 2025)</li>
              <li>Spot the fake: Large multimodal model-based synthetic image detection with artifact explanation (Arxiv 2025)</li>
            </ul>
          </div>
        </div>

        

        <hr style="margin-top: 3em; margin-bottom: 2em;">
        <h2>Joint Training Students</h2>
        
        <div class="students-grid">
          <div class="student-card">
            <h3>Hengrui Kang (康恒锐)</h3>
            <p><strong>Current Institution:</strong> Undergraduate from Honors College, University of Electronic Science and Technology of China (UESTC)</p>
            <p><strong>Joint Ph.D. Program:</strong> Shanghai Jiao Tong University (SJTU) & Shanghai AI Laboratory (Currently 1st-year Ph.D. student)</p>
            <p><strong>Internship Experience:</strong> Joined OpenDataLab as an intern in early December 2023</p>
            <p><strong>Key Work:</strong> Participated in the lab's intelligent document parsing (MinerU project) and has made preliminary explorations in Trustworthy AI (synthetic image detection).</p>
            <p><strong>Research Interests:</strong> Synthetic data detection, intelligent document parsing and generation</p>
          </div>

          <div class="student-card">
            <h3>Jiahe Song (宋家和)</h3>
            <p><strong>Current Institution:</strong> Third-year Master's student, School of Computer Science, Peking University (PKU)</p>
            <p><strong>Joint Ph.D. Program:</strong> School of AI, Shanghai Jiao Tong University (SJTU) & Shanghai AI Laboratory (Starting Sep 2025)</p>
            <p><strong>Internship Experience:</strong> Started internship at Shanghai AI Laboratory (Beijing base) in October 2024 (Advisor: Dr. Jiang Wu)</p>
            <p><strong>Key Work:</strong> Co-first author of the paper "PM4Bench: A Parallel Multilingual Multi-Modal Multi-task Benchmark for Large Vision Language Model"</p>
            <p><strong>Research Interests:</strong> Multimodal large models, AI for science</p>
          </div>

          <div class="student-card">
            <h3>Honglin Lin (林泓霖)</h3>
            <p><strong>Current Institution:</strong> Final-year undergraduate student, Artificial Intelligence, Beijing University of Posts and Telecommunications (BUPT)</p>
            <p><strong>Joint Ph.D. Program:</strong> School of AI, Shanghai Jiao Tong University (SJTU) & Shanghai AI Laboratory (Starting Sep 2025)</p>
            <p><strong>Internship Experience:</strong> Has been interning at the lab for over half a year since postgraduate recommendation in 2024</p>
            <p><strong>Research Interests:</strong> Mathematical reasoning in large models, data synthesis, etc.</p>
          </div>

          <div class="student-card">
            <h3>Junbo Niu (牛俊博)</h3>
            <p><strong>Current Institution:</strong> Final-year undergraduate student, Automation, Beihang University</p>
            <p><strong>Joint Ph.D. Program:</strong> Peking University (PKU) & Shanghai AI Laboratory (Starting Sep 2025)</p>
            <p><strong>Research Interests:</strong> Multimodal Understanding (Video Understanding, OCR) & Data-Centric Machine Learning</p>
          </div>

          <div class="student-card">
            <h3>Xin Gao (高鑫)</h3>
            <p><strong>Current Institution:</strong> Software Engineering, University of Electronic Science and Technology of China (UESTC)</p>
            <p><strong>Joint Ph.D. Program:</strong> Shanghai Jiao Tong University (SJTU) & Shanghai AI Laboratory (Starting Sep 2025)</p>
            <p><strong>Internship Experience:</strong> Joined the lab as an intern in early August 2024</p>
            <p><strong>Research Interests:</strong> Data synthesis, evaluation, and filtering for large models, etc.</p>
          </div>

          <div class="student-card">
            <h3>Yu Li (李宇)</h3>
            <p><strong>Current Institution:</strong> Final-year undergraduate student, School of Cyber Science and Engineering, Wuhan University</p>
            <p><strong>Joint Ph.D. Program:</strong> University of Science and Technology of China (USTC) & Shanghai AI Laboratory (Starting Sep 2025)</p>
            <p><strong>Internship Experience:</strong> Joined the lab as an intern at the end of October 2024</p>
            <p><strong>Research Interests:</strong> Logical reasoning in large models, data synthesis, etc.</p>
          </div>

          <div class="student-card">
            <h3>Zichen Wen (温子辰)</h3>
            <p><strong>Current Institution:</strong> Undergraduate from University of Electronic Science and Technology of China (UESTC)</p>
            <p><strong>Joint Ph.D. Program:</strong> Shanghai AI Laboratory & Shanghai Jiao Tong University (SJTU) (Starting Sep 2025)</p>
            <p><strong>Research Interests:</strong> Efficient AI (including Lightweight and Efficient Large Models for Language/Multimodality, and Data-Efficient Artificial Intelligence)</p>
          </div>
        </div>

      </div>
    </section>
  </main>
  
  <footer>
    <div class="container">
      <div class="footer-content">
        <div class="footer-contact">
          <p>Shanghai Artificial Intelligence Laboratory · OpenDataLab | Email: xxxxxxx</p>
        </div>
        <div class="footer-copyright">
          <p>Copyright © 2025 OpenDataLab | All Rights Reserved</p>
        </div>
      </div>
    </div>
  </footer>
</body>
</html> 